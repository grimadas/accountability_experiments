{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Smart detection with blocks knowledge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import csv\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import collections\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# Load a snapshot of a network \n",
    "G = nx.read_gpickle('trustchain.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Eventually consistent Ledger for P2P "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "\n",
    "We don't want to use global consensus algorithms (i.e. BFT based on voting, or exchanging a lot of redundant information). Such consensus algorithms are not scalable either in a number of peers or throughput.\n",
    "An implicit consensus with related peers might work. \n",
    "\n",
    "\n",
    "I have studied applications where Trustchain can shine and very few require strong consistency on the events. \n",
    "Identity, bandwidth exchange and ledger and ATMs in banks don't have strong consistency. They allow marginal quantifiable error in exchange for availability and scalability.\n",
    "\n",
    "There is practically no need to use a totally ordered set(Chain) even for one account. We need to look into the partially/casually ordered set. There is no dependency between getting bandwidth from two peers, such events can easily happen in parallel. Using a totally ordered requires and even forces peer to sync on a counter, it is like using a lock, it is easy and does it is the thing, but it is a huge overkill for most of the applications.  \n",
    "\n",
    "What we want is to quantify the risk double-spending, or to put more generally we want to minimize the ability to hide some information from the other peer. Having near full information is crucial to the decision making the process of the peer. So don't need the full ordering of the event but knowledge completeness.  \n",
    "\n",
    "\n",
    "To guarantee eventual consistency with quantifiable risk: \n",
    " 1. Each peer must share to the network the event \n",
    " \n",
    "  - If the event is not shared in the network it is impossible to protect/mitigate hiding\n",
    "  - To save bandwidth the event must be shared in the network with the peers that are interested/subscribed for this information\n",
    "  - Peer must known at least `f+1` peer that are related to an account `A` - *witnesses*. Peer that had/or have common history with `A`.   \n",
    "  \n",
    " 2. Each transaction must be build on top of the lastest state(lastest set of known events)\n",
    " \n",
    "  - This guarantees that block cannot be hidden and all related peers will eventaully converge to the same common state\n",
    "  - The state is presented with a partially ordered set *PoSet* - this is enough to gurantee convergance, but they are usually much more parallel-friendly. DS to test out: **DAG-CHAIN, Vector(Bloom)Clock, Merkle tree variants**. Each of these data structures are used to compactly accumulate sets of parially ordered sets. \n",
    "  \n",
    " 3. The consistency of the system is formed as following: \n",
    " \n",
    "   - We need to maintain a system invariant, for example account balance must be positive and etc.\n",
    "   - Some invariants are easy to maintain in eventual world: For example growing only counter and a low bound\n",
    "   - We can guarantee invariants by pre-conditions of each transaction\n",
    "   - Some applications require strict consitency - no invariant violation, but some are less strict on that, we aim for these applications.\n",
    "   - There several ways to achieve just-enough consistency for invariants: \n",
    "       1. Smaller transactions when approaching the invariant bound \n",
    "       2. Give the consistency completly, but don't serve/... when invariant is broken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# Tribler token ledger \n",
    "# Creating a Token Economy for Anonymous bandwidth sharing \n",
    "# Anonymous network -> well-defined operations \n",
    "\n",
    "# Accounting mechanisms \n",
    "# Making the accounting mechanisms useful \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def store_transaction(ledger, tx):\n",
    "    '''\n",
    "    Store transaction in the local ledger\n",
    "    '''\n",
    "    tx['from']\n",
    "    tx['count']\n",
    "    tx['to']\n",
    "    tx['hash']\n",
    "    tx['prev_hash']\n",
    "    tx['sig']\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "   A: Bloom filter A increase with operation in B $H_k(B)+=1$\n",
    "   \n",
    "   B: Confirm that B received and update it's state $H_k(A)+=1$\n",
    "   \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "General Transaction format: `from, to, payload(count), hash, signature`\n",
    "\n",
    "\n",
    "## 0. Store in a Account - Chain with a counter\n",
    "\n",
    "Store as it stored now - all events realted to account are connected in a totally ordered chain. \n",
    "\n",
    "When peer recieves a new transaction with an inclusion proof it can download necessary transaction from local head to current head in the transaction. \n",
    "\n",
    "**Inclusion proof:**\n",
    "\n",
    "1. Each transaction has a chained has based on a continously chaining hash root of a Account Chain \n",
    "\n",
    "**Validation:**\n",
    "\n",
    "- To validate peer will rebuild it's own local chain by donwloading realted transactions.\n",
    "- Peer constructs chain  from the last head to the current head, if it find some inconsistency it will suspect peer B that it changed the chain / or it was restructured? Possible strategies:\n",
    " + Ask other peer about the chain - local quorum consensus \n",
    " + Keep transactions from peer B \n",
    "- When peer A sees a counter it must download other transactions from other peer it is able to download from peer B or if it sees that transaction is a confirmation transaction from peer C, it may request state from peer C.\n",
    "- Some transaction might not be confirmed but they are part of the chain so peer A cannot hide it. \n",
    "\n",
    "**Double spending scenario:** \n",
    " \n",
    "1. Peer A is double spending and peer B and peer C is estimating double spend probability etc.  \n",
    "- Peer A creates a source block b and another block b' with the same previous hash for both blocks\n",
    "- This can be detected but no scheme to reconstruct, restructure the chain: \n",
    " + DAG: Continue as a dag, allow multiple previous heads \n",
    " \n",
    " \n",
    "***How to compress the chain?*** \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Quickly synchronize when you out of sync and detect the chain holes/ difference?**\n",
    "\n",
    "Transaction in this case includes a counter that show the order in the chain. When peer receives a transactions out of order\n",
    "it can't apply it before downloading other blocks. This makes other peers wait for the synchronization, \n",
    "but decreases double spend probability?   \n",
    "\n",
    "Double spend will be eventually detected because of the previous layer, \n",
    "but it is unclear how to recover from the double spend, as in the chain there must be only one ground true.\n",
    "\n",
    "### Chain-Lattice: \n",
    "Store counters per peer-interactions: \n",
    "See `Vector clock`\n",
    "\n",
    "Store transactions in a chain, but the counter is per-interaction.\n",
    " \n",
    "#### Why?\n",
    "\n",
    "\n",
    "### 0.1 Chain-DAG modification\n",
    "\n",
    "A transaction can include multiple links to the transactions. Inclusion of a link means that it is know. \n",
    "Each transaction will have multiple previous links - for a merging semantics. \n",
    "\n",
    "#### Merge semantics\n",
    "\n",
    "Transaction includes multiple links from last seen chains\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## 1. Store in a vector clock\n",
    "\n",
    "Suppose that we can limit number of account and which are static. \n",
    "\n",
    "$VC_A = {0, 0, 0 \\dots 0}$\n",
    "\n",
    "Transfer to $B --> VC_A(B)+=1$\n",
    "\n",
    "Each transaction increases a counter of counter-account. Each account update is independent This can be performed indepdently from each other.   \n",
    "\n",
    "Basically account chain with a counter is partially a vector clock. \n",
    "\n",
    "**Inclusion Proof:** \n",
    "\n",
    " 1. Full vector clock in a block: all accounts clock \n",
    "  - This helps to quickly synchronize for other peers, but a lot redundant information is exchanged.  \n",
    " 2. Delta in a vector clock. For example, just a simple counter is enough. B: 34 -> 35 \n",
    "  - When other peer sees this update, it can learn if it is synchrnoized with information regarding to B. \n",
    "\n",
    "**Downsides**:\n",
    " - *Not scalable in number of accounts*\n",
    " - *Big message number to exchange* \n",
    " \n",
    "**Validation**:\n",
    " - Verifiy that vector clock is recent and known, aka can be reconstructed from the local clock\n",
    " \n",
    "\n",
    "### 1.1. Bloom clock modification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## 2. Store in a Merkle Tree\n",
    "\n",
    "Merkle tree can be used to compress transaction into a merkle root with a state sketch.\n",
    "\n",
    "Each transaction will include a resulting merkle root. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "When considereing an application you need to think first what need to be consistent: \n",
    " \n",
    " Think in invariants: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Related work\n",
    "## Set-reconcilation with cuckoo filters\n",
    "\n",
    "### One filter per account?\n",
    "\n",
    "The performance of the filter will degrade with more values inserted. \n",
    "To improve performance we need to introduce moving window of the elements, or limit the number of transactions. \n",
    "\n",
    "Filter will be filled with transaction id/hash. \n",
    "\n",
    "Having a filter and a new transaction one can check quickly if the transacion is inserted in the right time. \n",
    "Bloom clock \n",
    "\n",
    "## Transaction \n",
    "\n",
    "Source transaction: Account $A$ is making a sending bandwith transaction to $B$:\n",
    "   \n",
    "   Transaction id: $T_{id}$, update to state $A$ and to state $B$  \n",
    "\n",
    "\n",
    "Transaction is a state transaction of a Peer A from $T_k: s_k -> s_{k+1}$. \n",
    "\n",
    "State can be represented as a Bloom clock? Counting Bloom Filter or Cuckoo filter\n",
    "\n",
    "Each peer has own clock, event happend can be computed -> $H_k(B)+=1$ for each $H_k$. This will update certain cells in the clock. \n",
    "\n",
    "Transactions with different peers can be executed concurrently and later merged. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
