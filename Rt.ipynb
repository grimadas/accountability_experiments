{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Smart detection with blocks knowledge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import csv\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import collections\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# Load a snapshot of a network \n",
    "G = nx.read_gpickle('trustchain.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Eventually consistent Ledger for P2P "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "\n",
    "We don't want to use global consensus algorithms (i.e. BFT based on voting, or exchanging a lot of redundant information). Such consensus algorithms are not scalable either in a number of peers or throughput.\n",
    "An implicit consensus with related peers might work. \n",
    "\n",
    "\n",
    "I have studied applications where Trustchain can shine and very few require strong consistency on the events. \n",
    "Identity, bandwidth exchange and ledger and ATMs in banks don't have strong consistency. They allow marginal quantifiable error in exchange for availability and scalability.\n",
    "\n",
    "There is practically no need to use a totally ordered set(Chain) even for one account. We need to look into the partially/casually ordered set. There is no dependency between getting bandwidth from two peers, such events can easily happen in parallel. Using a totally ordered requires and even forces peer to sync on a counter, it is like using a lock, it is easy and does it is the thing, but it is a huge overkill for most of the applications.  \n",
    "\n",
    "What we want is to quantify the risk double-spending, or to put more generally we want to minimize the ability to hide some information from the other peer. Having near full information is crucial to the decision making the process of the peer. So don't need the full ordering of the event but knowledge completeness.  \n",
    "\n",
    "\n",
    "To guarantee eventual consistency with quantifiable risk: \n",
    " 1. Each peer must share to the network the event \n",
    " \n",
    "  - If the event is not shared in the network it is impossible to protect/mitigate hiding\n",
    "  - To save bandwidth the event must be shared in the network with the peers that are interested/subscribed for this information\n",
    "  - Peer must known at least `f+1` peer that are related to an account `A` - *witnesses*. Peer that had/or have common history with `A`.   \n",
    "  \n",
    " 2. Each transaction must be build on top of the lastest state(lastest set of known events)\n",
    " \n",
    "  - This guarantees that block cannot be hidden and all related peers will eventaully converge to the same common state\n",
    "  - The state is presented with a partially ordered set *PoSet* - this is enough to gurantee convergance, but they are usually much more parallel-friendly. DS to test out: **DAG-CHAIN, Vector(Bloom)Clock, Merkle tree variants**. Each of these data structures are used to compactly accumulate sets of parially ordered sets. \n",
    "  \n",
    " 3. The consistency of the system is formed as following: \n",
    " \n",
    "   - We need to maintain a system invariant, for example account balance must be positive and etc.\n",
    "   - Some invariants are easy to maintain in eventual world: For example growing only counter and a low bound\n",
    "   - We can guarantee invariants by pre-conditions of each transaction\n",
    "   - Some applications require strict consitency - no invariant violation, but some are less strict on that, we aim for these applications.\n",
    "   - There several ways to achieve just-enough consistency for invariants: \n",
    "       1. Smaller transactions when approaching the invariant bound \n",
    "       2. Give the consistency completly, but don't serve/... when invariant is broken\n",
    "\n",
    "\n",
    "We need a data structure that will combine deltas into one compressed represention. \n",
    "\n",
    "Naive option: \n",
    " - Store deltas of transactions in a set \n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# Tribler token ledger \n",
    "# Creating a Token Economy for Anonymous bandwidth sharing \n",
    "# Anonymous network -> well-defined operations \n",
    "\n",
    "# Accounting mechanisms \n",
    "# Making the accounting mechanisms useful \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "   A: Bloom filter A increase with operation in B $H_k(B)+=1$\n",
    "   \n",
    "   B: Confirm that B received and update it's state $H_k(A)+=1$\n",
    "   \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "General Transaction format: `from, to, payload(count), hash, signature`\n",
    "\n",
    "\n",
    "## 0. Store in a Account - Chain with a counter\n",
    "\n",
    "Store as it stored now - all events realted to account are connected in a totally ordered chain. \n",
    "\n",
    "When peer recieves a new transaction with an inclusion proof it can download necessary transaction from local head to current head in the transaction. \n",
    "\n",
    "**Inclusion proof:**\n",
    "\n",
    "1. Each transaction has a chained has based on a continously chaining hash root of a Account Chain \n",
    "\n",
    "**Validation:**\n",
    "\n",
    "- To validate peer will rebuild it's own local chain by donwloading realted transactions.\n",
    "- Peer constructs chain  from the last head to the current head, if it find some inconsistency it will suspect peer B that it changed the chain / or it was restructured? Possible strategies:\n",
    " + Ask other peer about the chain - local quorum consensus \n",
    " + Keep transactions from peer B \n",
    "- When peer A sees a counter it must download other transactions from other peer it is able to download from peer B or if it sees that transaction is a confirmation transaction from peer C, it may request state from peer C.\n",
    "- Some transaction might not be confirmed but they are part of the chain so peer A cannot hide it. \n",
    "\n",
    "**Double spending scenario:** \n",
    " \n",
    "1. Peer A is double spending and peer B and peer C is estimating double spend probability etc.  \n",
    "- Peer A creates a source block b and another block b' with the same previous hash for both blocks\n",
    "- This can be detected but no scheme to reconstruct, restructure the chain: \n",
    " + DAG: Continue as a dag, allow multiple previous heads \n",
    " \n",
    " \n",
    "***How to compress the chain?*** \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Quickly synchronize when you out of sync and detect the chain holes/ difference?**\n",
    "\n",
    "Transaction in this case includes a counter that show the order in the chain. When peer receives a transactions out of order\n",
    "it can't apply it before downloading other blocks. This makes other peers wait for the synchronization, \n",
    "but decreases double spend probability?   \n",
    "\n",
    "Double spend will be eventually detected because of the previous layer, \n",
    "but it is unclear how to recover from the double spend, as in the chain there must be only one ground true.\n",
    "\n",
    "### Chain-Lattice: \n",
    "Store counters per peer-interactions: \n",
    "See `Vector clock`\n",
    "\n",
    "Store transactions in a chain, but the counter is per-interaction.\n",
    " \n",
    "#### Why?\n",
    "\n",
    "\n",
    "### 0.1 Chain-DAG modification\n",
    "\n",
    "A transaction can include multiple links to the transactions. Inclusion of a link means that it is know. \n",
    "Each transaction will have multiple previous links - for a merging semantics. \n",
    "\n",
    "#### Merge semantics\n",
    "\n",
    "Transaction includes multiple links from last seen chains\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## 1. Store in a vector clock\n",
    "\n",
    "Suppose that we can limit number of account and which are static. \n",
    "\n",
    "$VC_A = {0, 0, 0 \\dots 0}$\n",
    "\n",
    "Transfer to $B --> VC_A(B)+=1$\n",
    "\n",
    "Each transaction increases a counter of counter-account. Each account update is independent This can be performed indepdently from each other.   \n",
    "\n",
    "Basically account chain with a counter is partially a vector clock. \n",
    "\n",
    "**Inclusion Proof:** \n",
    "\n",
    " 1. Full vector clock in a block: all accounts clock \n",
    "  - This helps to quickly synchronize for other peers, but a lot redundant information is exchanged.  \n",
    " 2. Delta in a vector clock. For example, just a simple counter is enough. B: 34 -> 35 \n",
    "  - When other peer sees this update, it can learn if it is synchrnoized with information regarding to B. \n",
    "\n",
    "**Downsides**:\n",
    " - *Not scalable in number of accounts*\n",
    " - *Big message number to exchange* \n",
    " \n",
    "**Validation**:\n",
    " - Verifiy that vector clock is recent and known, aka can be reconstructed from the local clock\n",
    " \n",
    "\n",
    "### 1.1. Bloom clock modification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## 2. Store in a Merkle Tree\n",
    "\n",
    "Merkle tree can be used to compress transaction into a merkle root with a state sketch.\n",
    "\n",
    "Each transaction will include a resulting merkle root. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "When considereing an application you need to think first what need to be consistent: \n",
    " \n",
    " Think in invariants: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Latency experiments and Sybils\n",
    "\n",
    "We make a simulation experiment on latency taken from PlanetLab dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_p = 490\n",
    "\n",
    "real_matrix = np.ndarray(shape=(n_p,n_p), dtype=float)\n",
    "\n",
    "\n",
    "with open(\"noodles/NetLatency-Data/PlanetLab/PlanetLabData_1\", 'r') as fw:\n",
    "    l_n = 0\n",
    "    for line in fw: \n",
    "        c_n = 0\n",
    "        for val in line.split('\\t'):  \n",
    "            real_matrix[l_n][c_n] = val\n",
    "            c_n += 1\n",
    "        l_n += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D Cast evaluation\n",
    "\n",
    "\n",
    "Allow to interact with a peer for a limited number of blocks. \n",
    "\n",
    "It follows several phases: \n",
    "\n",
    "1. Establishment of a link. When establishing a link first peer must prove itself. It will prove itself by sending junk blocks. \n",
    "\n",
    "2. Junk blocks allow to establish a dept-link to request blocks. \n",
    "\n",
    "3. When peer `A` send block it will also send a dept ticket. The link cannot be used until the ticket is fully payed. Payment is with the a block in which the peer is interested in. \n",
    "\n",
    "4. The payment is when `A` requests `B` for certain transactions that `A` witneesed. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "It works with dept coins that work as effective punishment. No block can be requested until the dept is not payed. \n",
    "\n",
    "- Doin payment is larger then doin issue \n",
    "- Peers are incentives to accept dept-link establishment, to fetch information quicker. \n",
    "- Incentivies peers exchange information quicker \n",
    "\n",
    " - The original ideas is based on the multicast trees for exchanging video pieces. \n",
    " - The dynamic set membership was not tested \n",
    " - The root always follows the protocol and is the only source of the messages \n",
    " - The root and peers have loosly syncronied clock.\n",
    "\n",
    " - Since any malicious node can send junk blocks to any non-deviating peer, no protection from target DoS is guaranteed. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## How would it work in a blockchain settings\n",
    "\n",
    "*Each node act as a relay of transactions that will connect two peers and help them to account each other.*\n",
    "\n",
    "*Some nodes will act as a replication and verification guarantors*\n",
    "\n",
    "*Question*: \n",
    " - *Who will store transactions? On one hand storing certain transaction will improve relaying, on the other hand we cannot give guarantees on replication. *\n",
    " - *Each account has different popularity and dynamics in the network*\n",
    " \n",
    "### Option 1: Peers has a list of subscriptions that is dynamically changing. \n",
    "\n",
    "- When peer enters the network defines a list of blocks that peer is interested in\n",
    "- \n",
    "\n",
    "### Option 2: Everybody must get everything \n",
    "\n",
    " - This is the case described in the original paper\n",
    " - **Problem: Malicious/Sybil peers will generate bogus content to pay for blocks**\n",
    " - Transaction fees? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we need \n",
    "\n",
    " - Rational peer wants to constrain the number of peers that he interacts with. Since you have to store and communicated with other peers.  \n",
    " - Sybils might be your interaction partners - colluders that will always work with you\n",
    " - Colluders might be your interaction partners - peer have to provide incentives for collusion \n",
    " - You have to be connected and not Eclipse attacked\n",
    " - We need to contrain the number of peer that each node has as a interaction partner\n",
    " - Who will act as a witness in the network, we need to assign somebody for storing and verifying transaction: witness will act as guarantee and replication. Replication and Verifcation guarntee \n",
    " - There should be way to verify the trust score towards a set of nodes. Verify Sybilneess probablity \n",
    " - Peers might refuse interacting with a peer. Is interaction a doubly signed? \n",
    " \n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction partners as your overlay view\n",
    "\n",
    "`A` --tx--> `B`\n",
    "`B` --confirm--> `A`\n",
    "\n",
    "To optimize the interaction you might connect directly to your interaction partner.\n",
    "When initiating a transaction you first sent to the peer, wait for response.\n",
    "When receving a response you notify all your interaction partners about the update of your balance. \n",
    "If you are counterparty you notify all you neighbours that your balance increased? \n",
    "\n",
    "### Transaction assumptions \n",
    "\n",
    "1. There are two types of transactions: `spend` and `confirm` \n",
    "2. `spend` transaction is valid on it's own and require no interaction with a counterparty \n",
    "\n",
    "3. `confirm` transaction require first `spend` transaction and is not valid otherwise\n",
    "\n",
    "4. `spend` is always a minus transaction, that will decrease the balance\n",
    "\n",
    "5. `confirm` is always a plus transaction, that will increase the balance\n",
    "\n",
    "6. There is incentive to hide `spend` transactions, to minimise the loss to the balance. Either spending multiple times the transaction, or completely hide it. \n",
    "\n",
    "\n",
    "7. There is incentive to use same `spend` transaction in multiple `confirm` transactions. \n",
    "\n",
    "\n",
    "`Double claim` \n",
    "is resolved with a chain synchronisation. And will be detected. \n",
    "With a determenstic rule - first transaction wins, further transaction are not valid and will not counted. \n",
    "\n",
    "`Double spend`\n",
    "is resolved with a network overlay\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### `A` can hide certain transaction from certain peers\n",
    "\n",
    "If `A` is the only point in the overlay that is connecting two peers all transactions will go through that peer and can be easly hidden from certain peers. \n",
    "\n",
    "For example, `A` has two honest peers `C` and `B`. Peer `A` sends same transaction to two peers, and hides balance from other peers. \n",
    "\n",
    "If `C` is honest it will follow the protocol and forward the information about the update it get. \n",
    "\n",
    "\n",
    "### If counterparty crashed/ not responding/hiding confirmation\n",
    "\n",
    " If A's balance depends on the response from `B` peer a might stuck with an unconfirmed transaction, hence this might be a liveness violation. \n",
    " #### Solution\n",
    "     \n",
    "   `A` optimistically sends `spend` thus declaring that he spent certain balance. \n",
    " \n",
    "   B might not receive the transaction. If B does not receive the transaction, peer cannot update the balance. Such transaction might be lost if not replicated enough. `B` is subscribed for all updates related to itself. We say that eventually B will receive transaction when it is back online and connected. \n",
    "   \n",
    " Since `A` has incentives to hide `spend` transaction it will not broadcast it. When B is online it will request updates on B and last neighbours.  If B will directly ask A and not confirm with others. A will inform about this transaction. But if B will receive transactions from other nodes, a double spend will be detected by B. \n",
    "   \n",
    "### How to restrict the number of peers that you interact with\n",
    "\n",
    "\n",
    "Each transaction is linked to the last block of the declaration. \n",
    "The transaction is not valid if it is not declared before. \n",
    "\n",
    "The risk is proportional to the number of peers and number of tokens allocated. \n",
    "\n",
    "#### Option 1: Unilateral declaration of intent\n",
    "\n",
    " - Peer declares intent to interact with following peers as one transaction <C, D, E, F>\n",
    " - All upcoming transaction should be linked to the list of declarion, otherwise they are not valid.  \n",
    " - This declartion can be forked, and can be changed quickly. \n",
    " \n",
    " Problem: \n",
    " _Peer declares Sybil commitee and hides it from other peers, at the same time it will interact with them_\n",
    "\n",
    " Solutions: \n",
    " 1. Wait for more confirmations from your neighbours. If they received it, you will get more confidence? Look at Avalance (Mixing slow and fast)\n",
    " - This requires to build up transactions on top of another transaction. \n",
    " \n",
    " \n",
    " 2. Connect futher transaction to the parters declaration. Each transaction is linked to the other chain. Peer continue interacting as normal. There two possible forks: now with transaction and with the commitee. \n",
    " - This might be intersting \n",
    "\n",
    " 3. Exchange with a gossip about others\n",
    " - Similar to hashgraph?\n",
    " \n",
    " 4. Declare one peer and promise certain tokens for this peer. The tokens will be virtually spent. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atomic payments\n",
    "\n",
    "Execute or rolle back the transaction \n",
    "\n",
    "1. Put funds on hold \n",
    "Notaries decide on faliure or success based on per-transaction basis \n",
    "\n",
    "\n",
    "### Universal mode with a risk \n",
    "\n",
    " - Define the expiry window. This defines `t` - expiration time for prepare-fulfill payment cycle. The expiration is depdndednt for the bilateral agreement party. \n",
    " - Denial of Service protection \n",
    " - Priority to the fullfillment - priority for the finalization over a prepartion \n",
    " - Payment bandwith - how to manage the bandwith: less bandwith to untrustworthy servers \n",
    " - Prefer smaller payments - plaace a smaller precentange on the collectors liguqityd on hold, carries less risk of failing the payment \n",
    " - Blacklisting senders and receivers: if the rate of failed payments is to high connecteor might refuse the payment \n",
    " \n",
    " \n",
    " \n",
    " **Limiting Risk:**\n",
    "\n",
    " + Total counterparty risk: limit the total value of unsettled payments, limit hte amount of money that counterparty could steal \n",
    " + Given a micropayemnt \n",
    " \n",
    "\n",
    "### Optimistic settlement \n",
    "\n",
    "\n",
    "After each time each peer settle a balance of the peer and decide if it wants to continue interacting with this peer. \n",
    "\n",
    "\n",
    "### Value streaming \n",
    "\n",
    "- Sending value and data \n",
    "- Segment payments into smaller packet \n",
    "- Bi-directional payments \n",
    "- Adjust the sending rate \n",
    "- Congestion control - adjust the rate based on the throughput limits \n",
    "- \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate the probability of double spending\n",
    "\n",
    "Suppose an honest peer X knows all neighbours of peer T S = {P_1, P_2, .. P_k, X}.\n",
    "\n",
    "\n",
    "Peer is connected through might be connected through some route. \n",
    "In S there is one honest peer except X. \n",
    "If the peer will send to all peers in the set with will guarantee that transaction can be detected. \n",
    "But this is unrealistic. \n",
    "\n",
    "Another approach is to send to some number of random peers this will guarantee with some probability the detection. \n",
    "\n",
    "But since the neighbor could be a Sybil node or a colluding node. It might hide a transaction of peer T to cheat X. You will connect to one of the niehgbours and report the transaction. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "To detect double spending peer \n",
    "\n",
    "\n",
    "\n",
    "To guarantee that double spend will be detected, where\n",
    "\n",
    "Peer must send to the peer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolution strategies\n",
    "\n",
    "\n",
    "\n",
    "Suppose `E` makes double spent with `C` and other `R` peers.\n",
    "Double spent will be detected eventually(when exactly?)\n",
    "\n",
    "\n",
    "We are trying to find a stable strategy that can continue without additional interaction and resolve conflicts optimistically. \n",
    "\n",
    "\n",
    "From the perspective of C following situations are possible: \n",
    "\n",
    "1. C will get nothing, R peers get nothing. Double spent transaction is not valid. \n",
    " - **If C is honest it will wait confirmation/sufficient time**\n",
    " - *C might sent same token to futher peer, increasing the complexity of resolution*\n",
    " - If `R` peers are Sybils/Colluding they might hide transaction from one region and present it to the different honest region, and repeat it multiple times. \n",
    " \n",
    " \n",
    "If node can create Sybil and send updates to them through a side channels, this strategy is not stable.\n",
    "\n",
    "2. C gets full balance anyway. \n",
    "\n",
    "This is possible in two situations: \n",
    " - When peer E has a oversupply of goods. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Choose start set\n",
    "\n",
    "### 1. Perfect start set\n",
    "\n",
    "We start with perfectly distribtued set that follows the distribution function.\n",
    "Greedy selection of your partners \n",
    "\n",
    "We say that the function should be 2(close) - 2(med) - 1(distant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vals = (10, 5, 5)\n",
    "max_deg = 30\n",
    "system_nodes = dict()\n",
    "neigh_nodes = dict()\n",
    "s1 = int(np.random.choice(range(n_p)))\n",
    "system_nodes[s1] = [0, 0, 0]\n",
    "neigh_nodes[s1] = set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_s1 = 0\n",
    "iters = 0\n",
    "while True:\n",
    "    \n",
    "    # Current candidate \n",
    "    s1 = sorted(((y, x) for x,y in system_nodes.items()))[iters][1]\n",
    "    if prev_s1 == 0:\n",
    "        prev_s1 = s1\n",
    "    else:\n",
    "        if prev_s1 == s1:\n",
    "            iters+=1 \n",
    "        else:\n",
    "            prev_s1 = s1\n",
    "    if iters > 30:\n",
    "        break\n",
    "    \n",
    "    if sum(system_nodes[s1]) > max_deg:\n",
    "        break\n",
    "    \n",
    "    # Find low peers first\n",
    "    val1 = np.argsort(real_matrix[s1])\n",
    "    \n",
    "    \n",
    "    sets = (set(np.random.choice(val1[1:50], vals[0])), \n",
    "            set(np.random.choice(val1[50:250], vals[1])), \n",
    "            set(np.random.choice(val1[250:450], vals[2])) )\n",
    "\n",
    "    for k in range(3):\n",
    "        if system_nodes[s1][k] >= vals[k]:\n",
    "            continue\n",
    "        for cand in set(system_nodes) & sets[k]:\n",
    "            if sum(system_nodes[cand]) < max_deg:\n",
    "                # candidate accepts the invite\n",
    "                system_nodes[cand][k] += 1\n",
    "                system_nodes[s1][k] += 1\n",
    "                neigh_nodes[s1] |=  {cand}\n",
    "                neigh_nodes[cand] |=  {s1}\n",
    "        if len(system_nodes) >= 50:\n",
    "            continue\n",
    "            \n",
    "        added_set = np.random.choice(list(sets[k] - set(system_nodes)), vals[k] - system_nodes[s1][k])\n",
    "        neigh_nodes[s1] |=  set(added_set)\n",
    "        system_nodes[s1][k] +=  len(added_set)\n",
    "        for i in added_set:\n",
    "            system_nodes[i] = [0, 0, 0]\n",
    "            system_nodes[i][k] += 1\n",
    "            neigh_nodes[i] = {s1}     \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in system_nodes:\n",
    "    if sum(system_nodes[k]) > max_deg:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_for_peer(my_peer, t_peer):\n",
    "    ping = real_matrix[my_peer][t_peer]\n",
    "    print(ping, \"To \", t_peer)\n",
    "    for i in neigh_nodes[t_peer]:\n",
    "        print(i, real_matrix[my_peer][i])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.69 To  480\n",
      "485 144.49\n",
      "200 67.217\n",
      "107 143.42\n",
      "236 38.36\n",
      "301 131.81\n",
      "143 15.006\n",
      "335 38.759\n",
      "315 40.65\n",
      "251 81.374\n",
      "25 26.714\n",
      "475 42.303\n",
      "63 29.576\n",
      "305.21 To  176\n",
      "226 62.051\n",
      "163 67.703\n",
      "5 136.59\n",
      "6 97.62\n",
      "198 109.86\n",
      "233 17.784\n",
      "205 67.182\n",
      "78 221.2\n",
      "399 67.361\n",
      "63.192 To  7\n",
      "65 221.18\n",
      "6 97.62\n",
      "313 108.01\n",
      "200 67.217\n",
      "236 38.36\n",
      "205 67.182\n",
      "78 221.2\n",
      "399 67.361\n",
      "48 123.56\n",
      "372 93.153\n",
      "311 46.732\n",
      "183 102.83\n",
      "287 125.98\n",
      "98.814 To  56\n",
      "65 221.18\n",
      "483 163.7\n",
      "131 93.312\n",
      "5 136.59\n",
      "6 97.62\n",
      "485 144.49\n",
      "200 67.217\n",
      "233 17.784\n",
      "330 62.797\n",
      "236 38.36\n",
      "205 67.182\n",
      "315 40.65\n",
      "372 93.153\n",
      "311 46.732\n",
      "475 42.303\n",
      "63 29.576\n",
      "40.65 To  315\n",
      "480 33.69\n",
      "449 107.59\n",
      "485 144.49\n",
      "56 98.814\n",
      "200 67.217\n",
      "63 29.576\n",
      "62.051 To  226\n",
      "65 221.18\n",
      "322 57.901\n",
      "378 41.162\n",
      "251 81.374\n",
      "176 305.21\n",
      "335 38.759\n",
      "183 102.83\n",
      "474 42.23\n",
      "475 42.303\n",
      "311 46.732\n",
      "123.56 To  48\n",
      "63 29.576\n",
      "243 168.34\n",
      "117 110.72\n",
      "5 136.59\n",
      "7 63.192\n",
      "54 120.36\n",
      "233 17.784\n",
      "301 131.81\n",
      "200 67.217\n",
      "38.759 To  335\n",
      "480 33.69\n",
      "226 62.051\n",
      "25 26.714\n",
      "236 38.36\n",
      "383 95.156\n",
      "144.49 To  485\n",
      "480 33.69\n",
      "287 125.98\n",
      "105 143.82\n",
      "301 131.81\n",
      "143 15.006\n",
      "239 100.65\n",
      "84 291.36\n",
      "117 110.72\n",
      "183 102.83\n",
      "56 98.814\n",
      "313 108.01\n",
      "315 40.65\n",
      "25 26.714\n",
      "383 95.156\n",
      "125.98 To  287\n",
      "483 163.7\n",
      "485 144.49\n",
      "6 97.62\n",
      "7 63.192\n",
      "393 105.7\n",
      "239 100.65\n",
      "208 131.15\n",
      "117 110.72\n",
      "25 26.714\n",
      "475 42.303\n"
     ]
    }
   ],
   "source": [
    "# Malicious Identity joins the network\n",
    "start_peers = np.random.choice(list(system_nodes), 10)\n",
    "m = np.random.choice(list(set(range(n_p)) - set(system_nodes)))\n",
    "\n",
    "\n",
    "for k in start_peers:\n",
    "    # my ping to start peer\n",
    "    ask_for_peer(m, k)\n",
    "    # ask for neigh nodes \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_set_matrix = np.ndarray(shape=(len(start_set),len(start_set)), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for k in start_set:\n",
    "    j = 0\n",
    "    for p in start_set:\n",
    "        start_set_matrix[i][j] = real_matrix[k][p]\n",
    "        j+=1\n",
    "    i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  New node joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_nodes = start_set\n",
    "\n",
    "choice_set = list(set(range(n_p)) - system_nodes)\n",
    "\n",
    "new = int(np.random.choice(choice_set))\n",
    "system_nodes |= {new}\n",
    "\n",
    "\n",
    "# pick neighbours and verify them on sybilness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We choose starting set \n",
    "n_boot = 10\n",
    "start_set = np.random.choice(range(n_p), n_boot, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf = start_set[0]\n",
    "latencies = []\n",
    "for i in set(start_set)-{inf}:\n",
    "    latencies.append(real_matrix[inf, i])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inf = start_set[0]\n",
    "latencies = []\n",
    "for i in set(start_set)-{inf}:\n",
    "    latencies.append(real_matrix[inf, i])\n",
    "\n",
    "x = sorted(latencies, reverse=True)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "n, bins, rectangles = ax.hist(x, 5, density=False)\n",
    "fig.canvas.draw()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Related work\n",
    "## Set-reconcilation with cuckoo filters\n",
    "\n",
    "### One filter per account?\n",
    "\n",
    "The performance of the filter will degrade with more values inserted. \n",
    "To improve performance we need to introduce moving window of the elements, or limit the number of transactions. \n",
    "\n",
    "Filter will be filled with transaction id/hash. \n",
    "\n",
    "Having a filter and a new transaction one can check quickly if the transacion is inserted in the right time. \n",
    "Bloom clock \n",
    "\n",
    "## Transaction \n",
    "\n",
    "Source transaction: Account $A$ is making a sending bandwith transaction to $B$:\n",
    "   \n",
    "   Transaction id: $T_{id}$, update to state $A$ and to state $B$  \n",
    "\n",
    "\n",
    "Transaction is a state transaction of a Peer A from $T_k: s_k -> s_{k+1}$. \n",
    "\n",
    "State can be represented as a Bloom clock? Counting Bloom Filter or Cuckoo filter\n",
    "\n",
    "Each peer has own clock, event happend can be computed -> $H_k(B)+=1$ for each $H_k$. This will update certain cells in the clock. \n",
    "\n",
    "Transactions with different peers can be executed concurrently and later merged. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
